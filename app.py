#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„ ì–´í”Œë¦¬ì¼€ì´ì…˜
- ì–¼êµ´: ì‹¤ì‹œê°„ ì›¹ìº  ë¶„ì„ (í™”ë©´ì— ê³„ì† ë°˜ì˜)
- ìŒì„±: ìŒì„± ì…ë ¥ ì‹œì—ë§Œ ë¶„ì„
- GPT: ìŒì„± ì…ë ¥ ì‹œ 3ê°œ ëª¨ë‹¬ë¦¬í‹°(ì–¼êµ´+ìŒì„±+í…ìŠ¤íŠ¸) ëª¨ë‘ ì‚¬ìš©
"""

from flask import Flask, render_template, jsonify, request, Response
from flask_cors import CORS
import threading
import queue
import time
import numpy as np
import json
import logging
from datetime import datetime
from openai import OpenAI
import cv2
import os
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê¸°ì¡´ ëª¨ë¸ ì„í¬íŠ¸
from models import EMOTIONS
from models.face_emotion_model import FaceEmotionAnalyzer
from models.voice_emotion_model import VoiceEmotionAnalyzer
from models.text_emotion_model import TextEmotionAnalyzer
from main import LateFusion

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì „ì—­ ìƒìˆ˜
FUSION_INTERVAL = 2.0  # Late Fusion ê°„ê²© (2ì´ˆ)
CHAT_PERSONALITY = """ë‹¹ì‹ ì€ ê³µê°ì ì´ê³  ë”°ëœ»í•œ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ê°ì •ì„ ì´í•´í•˜ê³  ìœ„ë¡œì™€ ê²©ë ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

**ì¤‘ìš”**: ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ì€ Late Fusion ê¸°ìˆ ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.
- ì–¼êµ´ í‘œì • (ResNet18, 74% ì •í™•ë„) - ì‹¤ì‹œê°„ ì›¹ìº  ë¶„ì„
- ìŒì„± í†¤ (Wav2Vec2, 65% ì •í™•ë„) - ìŒì„± ì…ë ¥ ì‹œ ë¶„ì„
- í…ìŠ¤íŠ¸ ë‚´ìš© (KoBERT, 66% ì •í™•ë„) - ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜

ì´ ì„¸ ê°€ì§€ ëª¨ë‹¬ë¦¬í‹°ë¥¼ ê°€ì¤‘ í‰ê· í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„ëœ ê°ì • ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 
ì‚¬ìš©ìì˜ ì§„ì§œ ê°ì • ìƒíƒœë¥¼ íŒŒì•…í•˜ê³  ì ì ˆí•˜ê²Œ ë°˜ì‘í•˜ì„¸ìš”.

ê°ì • ë¶„í¬ë¥¼ ì°¸ê³ í•˜ì—¬:
- ì£¼ìš” ê°ì •ì— ê³µê°í•˜ë˜, ë‹¤ë¥¸ ê°ì •ë“¤ë„ ê³ ë ¤í•˜ì„¸ìš”
- ê°ì •ì´ í˜¼ì¬ëœ ê²½ìš° ë³µí•©ì ìœ¼ë¡œ ì´í•´í•˜ì„¸ìš”
- ì‹¤ì‹œê°„ ì–¼êµ´ í‘œì • ë³€í™”ë¥¼ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”"""

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    logger.info("ChatGPT ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    client = None
else:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ê°ì • ë°ì´í„° í (SSEìš©)
emotion_queue = queue.Queue(maxsize=100)

# ì±„íŒ… íˆìŠ¤í† ë¦¬
chat_history = []


class RealtimeEmotionService:
    """ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.is_running = False
        self.face_thread = None
        self.fusion_thread = None
        
        # Late Fusion ì´ˆê¸°í™”
        self.late_fusion = LateFusion(interval=FUSION_INTERVAL)
        
        # ìµœì‹  ê°ì • ë°ì´í„°
        self.latest_emotions = {
            "happy": 0.2,
            "depressed": 0.2,
            "surprised": 0.2,
            "angry": 0.2,
            "neutral": 0.2
        }
        
        # ìµœì‹  ëª¨ë‹¬ë¦¬í‹°ë³„ ê°ì • (ìŒì„± ì…ë ¥ ì‹œ ì‚¬ìš©)
        self.latest_face_emotion = None
        self.latest_voice_emotion = None
        self.latest_text_emotion = None
        
        # ëª¨ë¸ ë¡œë“œ
        try:
            logger.info("ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            self.face_analyzer = FaceEmotionAnalyzer()
            self.voice_analyzer = VoiceEmotionAnalyzer()
            self.text_analyzer = TextEmotionAnalyzer()
            logger.info("âœ… ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            self.models_loaded = True
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.models_loaded = False
    
    def start(self):
        """ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ ì‹œì‘"""
        if self.is_running:
            return
        
        self.is_running = True
        
        # ì–¼êµ´ ë¶„ì„ ìŠ¤ë ˆë“œ (ì‹¤ì‹œê°„)
        self.face_thread = threading.Thread(target=self._face_analysis_loop, daemon=True)
        self.face_thread.start()
        
        # Fusion ìŠ¤ë ˆë“œ
        self.fusion_thread = threading.Thread(target=self._fusion_loop, daemon=True)
        self.fusion_thread.start()
        
        logger.info("ğŸš€ ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ ì‹œì‘")
    
    def stop(self):
        """ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ ì¤‘ì§€"""
        self.is_running = False
        if self.face_thread:
            self.face_thread.join(timeout=2)
        if self.fusion_thread:
            self.fusion_thread.join(timeout=2)
        logger.info("ğŸ›‘ ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ ì¤‘ì§€")
    
    def _face_analysis_loop(self):
        """ì‹¤ì‹œê°„ ì–¼êµ´ ë¶„ì„ ë£¨í”„ (ì›¹ìº )"""
        if not self.models_loaded:
            logger.warning("ëª¨ë¸ ë¯¸ë¡œë“œ - ì–¼êµ´ ë¶„ì„ ìŠ¤í‚µ")
            return
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            logger.error("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info("ğŸ“¹ ì‹¤ì‹œê°„ ì–¼êµ´ ë¶„ì„ ì‹œì‘")
        
        while self.is_running:
            try:
                ret, frame = cap.read()
                if not ret:
                    time.sleep(0.1)
                    continue
                
                # ì–¼êµ´ ê°ì • ë¶„ì„
                result = self.face_analyzer.analyze_face(frame)
                
                if result is None:
                    time.sleep(0.1)
                    continue
                
                face_probs, _ = result
                
                if face_probs is not None:
                    # Late Fusion ë²„í¼ì— ì¶”ê°€
                    self.late_fusion.add_face_emotion(face_probs)
                    
                    # ìµœì‹  ì–¼êµ´ ê°ì • ì €ì¥
                    self.latest_face_emotion = {
                        EMOTIONS[i]: float(face_probs[i])
                        for i in range(len(EMOTIONS))
                    }
                
                time.sleep(0.1)  # 10 FPS
                
            except Exception as e:
                logger.error(f"ì–¼êµ´ ë¶„ì„ ì—ëŸ¬: {e}")
                time.sleep(1)
        
        cap.release()
        logger.info("ğŸ“¹ ì–¼êµ´ ë¶„ì„ ì¢…ë£Œ")
    
    def _fusion_loop(self):
        """Late Fusion ë£¨í”„ (2ì´ˆë§ˆë‹¤)"""
        while self.is_running:
            try:
                time.sleep(0.5)
                
                # Late Fusion ìˆ˜í–‰
                if self.late_fusion.should_fuse():
                    fusion_result = self.late_fusion.fuse_emotions()
                    if fusion_result is not None:
                        emotion, all_probs, modalities = fusion_result
                        
                        # ê°ì • ë°ì´í„° ì—…ë°ì´íŠ¸
                        self.latest_emotions = {
                            EMOTIONS[i]: float(all_probs[i])
                            for i in range(len(EMOTIONS))
                        }
                        
                        # SSE íì— í‘¸ì‹œ
                        emotion_data = {
                            "timestamp": datetime.now().isoformat(),
                            "emotions": self.latest_emotions,
                            "primary_emotion": emotion,
                            "modalities": modalities
                        }
                        
                        try:
                            emotion_queue.put_nowait(emotion_data)
                        except queue.Full:
                            emotion_queue.get()
                            emotion_queue.put_nowait(emotion_data)
                        
                        logger.info(f"ğŸ“Š ê°ì • ì—…ë°ì´íŠ¸: {emotion} ({self.latest_emotions[emotion]:.1%}) [ëª¨ë‹¬ë¦¬í‹°: {modalities}]")
                    
                    self.late_fusion.reset_buffers()
                
            except Exception as e:
                logger.error(f"Fusion ë£¨í”„ ì—ëŸ¬: {e}")
                time.sleep(1)
    
    def process_voice_input(self, text: str, audio_data=None):
        """
        ìŒì„± ì…ë ¥ ì²˜ë¦¬ (3ê°œ ëª¨ë‹¬ë¦¬í‹° ëª¨ë‘ ì‚¬ìš©)
        
        Args:
            text: ìŒì„±â†’í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼
            audio_data: ìŒì„± ì˜¤ë””ì˜¤ ë°ì´í„° (ì˜µì…˜)
        
        Returns:
            dict: 3ê°œ ëª¨ë‹¬ë¦¬í‹° ê°ì • ê²°ê³¼
        """
        if not text or not text.strip():
            return None
        
        result = {
            "face": self.latest_face_emotion,
            "voice": None,
            "text": None
        }
        
        try:
            # 1. í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„
            if self.models_loaded:
                text_probs = self.text_analyzer.analyze_text(text)
                if text_probs is not None:
                    self.late_fusion.add_text_emotion(text_probs)
                    result["text"] = {
                        EMOTIONS[i]: float(text_probs[i])
                        for i in range(len(EMOTIONS))
                    }
                    self.latest_text_emotion = result["text"]
            
            # 2. ìŒì„± ê°ì • ë¶„ì„ (audio_dataê°€ ìˆìœ¼ë©´)
            if audio_data is not None and self.models_loaded:
                voice_probs = self.voice_analyzer.analyze_audio(audio_data)
                if voice_probs is not None:
                    self.late_fusion.add_voice_emotion(voice_probs)
                    result["voice"] = {
                        EMOTIONS[i]: float(voice_probs[i])
                        for i in range(len(EMOTIONS))
                    }
                    self.latest_voice_emotion = result["voice"]
            
            # ë¡œê·¸ ì¶œë ¥
            logger.info(f"ğŸ¤ [ìŒì„± ì…ë ¥] {text}")
            if result["face"]:
                face_top = max(result["face"], key=result["face"].get)
                logger.info(f"   â”œâ”€ ì–¼êµ´: {face_top} ({result['face'][face_top]:.1%})")
            if result["voice"]:
                voice_top = max(result["voice"], key=result["voice"].get)
                logger.info(f"   â”œâ”€ ìŒì„±: {voice_top} ({result['voice'][voice_top]:.1%})")
            if result["text"]:
                text_top = max(result["text"], key=result["text"].get)
                logger.info(f"   â””â”€ í…ìŠ¤íŠ¸: {text_top} ({result['text'][text_top]:.1%})")
            
            return result
            
        except Exception as e:
            logger.error(f"ìŒì„± ì…ë ¥ ì²˜ë¦¬ ì—ëŸ¬: {e}")
            return result
    
    def process_text_input(self, text: str):
        """
        í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©)
        
        Args:
            text: ì…ë ¥ í…ìŠ¤íŠ¸
        
        Returns:
            dict: í…ìŠ¤íŠ¸ ê°ì • ê²°ê³¼
        """
        if not text or not text.strip():
            return None
        
        try:
            if self.models_loaded:
                text_probs = self.text_analyzer.analyze_text(text)
                if text_probs is not None:
                    self.late_fusion.add_text_emotion(text_probs)
                    
                    result = {
                        EMOTIONS[i]: float(text_probs[i])
                        for i in range(len(EMOTIONS))
                    }
                    
                    text_top = max(result, key=result.get)
                    logger.info(f"âŒ¨ï¸  [í…ìŠ¤íŠ¸ ì…ë ¥] {text}")
                    logger.info(f"   â””â”€ í…ìŠ¤íŠ¸: {text_top} ({result[text_top]:.1%})")
                    
                    return result
            
            return self.latest_emotions
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì—ëŸ¬: {e}")
            return self.latest_emotions
    
    def get_latest_emotions(self):
        """ìµœì‹  ê°ì • ë°ì´í„° ë°˜í™˜"""
        return self.latest_emotions
    
    def get_multimodal_emotions(self):
        """ëª¨ë‹¬ë¦¬í‹°ë³„ ìµœì‹  ê°ì • ë°˜í™˜"""
        return {
            "face": self.latest_face_emotion,
            "voice": self.latest_voice_emotion,
            "text": self.latest_text_emotion
        }


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
emotion_service = RealtimeEmotionService()


def get_chatgpt_response(user_message: str, fusion_emotions: dict, modality_emotions: dict = None) -> str:
    """ChatGPT APIë¡œ ê³µê°ì  ì‘ë‹µ ìƒì„±"""
    # API í‚¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
    if client is None:
        return "ChatGPT ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”."
    
    try:
        # Late Fusion ê²°ê³¼ íŒŒì‹±
        primary_emotion = max(fusion_emotions, key=fusion_emotions.get)
        emotion_confidence = fusion_emotions[primary_emotion]
        
        # ëª¨ë“  ê°ì • í™•ë¥  ì •ë ¬
        sorted_emotions = sorted(fusion_emotions.items(), key=lambda x: x[1], reverse=True)
        
        # ê°ì • ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        emotion_context = f"\n[Late Fusion ê°ì • ë¶„ì„ ê²°ê³¼]\n"
        emotion_context += f"ì£¼ìš” ê°ì •: {primary_emotion} ({emotion_confidence:.1%})\n"
        emotion_context += "ì „ì²´ ê°ì • ë¶„í¬:\n"
        for emotion, prob in sorted_emotions:
            emotion_context += f"  - {emotion}: {prob:.1%}\n"
        
        # ëª¨ë‹¬ë¦¬í‹°ë³„ ìƒì„¸ ì •ë³´ (ìŒì„± ì…ë ¥ ì‹œ)
        if modality_emotions:
            emotion_context += "\n[ëª¨ë‹¬ë¦¬í‹°ë³„ ë¶„ì„]\n"
            if modality_emotions.get("face"):
                face_top = max(modality_emotions["face"], key=modality_emotions["face"].get)
                emotion_context += f"ì–¼êµ´ í‘œì •: {face_top} ({modality_emotions['face'][face_top]:.1%})\n"
            if modality_emotions.get("voice"):
                voice_top = max(modality_emotions["voice"], key=modality_emotions["voice"].get)
                emotion_context += f"ìŒì„± í†¤: {voice_top} ({modality_emotions['voice'][voice_top]:.1%})\n"
            if modality_emotions.get("text"):
                text_top = max(modality_emotions["text"], key=modality_emotions["text"].get)
                emotion_context += f"í…ìŠ¤íŠ¸ ë‚´ìš©: {text_top} ({modality_emotions['text'][text_top]:.1%})\n"
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¤€ë¹„
        messages = [
            {"role": "system", "content": CHAT_PERSONALITY + emotion_context}
        ]
        
        # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ í¬í•¨
        for msg in chat_history[-6:]:
            messages.append(msg)
        
        # í˜„ì¬ ë©”ì‹œì§€
        messages.append({"role": "user", "content": user_message})
        
        # ChatGPT API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=300
        )
        
        assistant_message = response.choices[0].message.content
        
        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        chat_history.append({"role": "user", "content": user_message})
        chat_history.append({"role": "assistant", "content": assistant_message})
        
        return assistant_message
        
    except Exception as e:
        logger.error(f"ChatGPT API ì—ëŸ¬: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ğŸ’™"


# =============================================================================
# Flask ë¼ìš°íŠ¸
# =============================================================================

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('index.html')


@app.route('/api/emotions')
def get_emotions():
    """í˜„ì¬ ê°ì • ë°ì´í„° ë°˜í™˜"""
    emotions = emotion_service.get_latest_emotions()
    return jsonify({
        "timestamp": datetime.now().isoformat(),
        "emotions": emotions,
        "primary_emotion": max(emotions, key=emotions.get)
    })


@app.route('/api/emotions/stream')
def emotion_stream():
    """ì‹¤ì‹œê°„ ê°ì • ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° (SSE)"""
    def generate():
        logger.info("SSE í´ë¼ì´ì–¸íŠ¸ ì—°ê²°")
        
        # ì´ˆê¸° ë°ì´í„°
        initial_data = {
            "timestamp": datetime.now().isoformat(),
            "emotions": emotion_service.get_latest_emotions(),
            "primary_emotion": max(emotion_service.get_latest_emotions(), 
                                  key=emotion_service.get_latest_emotions().get)
        }
        yield f"data: {json.dumps(initial_data)}\n\n"
        
        # ì§€ì†ì  ì—…ë°ì´íŠ¸
        while True:
            try:
                data = emotion_queue.get(timeout=5)
                yield f"data: {json.dumps(data)}\n\n"
            except queue.Empty:
                yield f": keepalive\n\n"
            except GeneratorExit:
                logger.info("SSE í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
                break
    
    return Response(
        generate(),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )


@app.route('/api/chat', methods=['POST'])
def chat():
    """
    í†µí•© ì±„íŒ… API
    - ìŒì„±: 3ê°œ ëª¨ë‹¬ë¦¬í‹°(ì–¼êµ´+ìŒì„±+í…ìŠ¤íŠ¸) ëª¨ë‘ ì‚¬ìš©
    - í…ìŠ¤íŠ¸: í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
    """
    try:
        data = request.json
        user_message = data.get('message', '').strip()
        is_voice = data.get('is_voice', False)
        
        if not user_message:
            return jsonify({"error": "ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400
        
        modality_emotions = None
        
        if is_voice:
            # ìŒì„± ì…ë ¥: 3ê°œ ëª¨ë‹¬ë¦¬í‹° ëª¨ë‘ ì‚¬ìš©
            modality_emotions = emotion_service.process_voice_input(user_message)
        else:
            # í…ìŠ¤íŠ¸ ì…ë ¥: í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
            emotion_service.process_text_input(user_message)
        
        # Late Fusion ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        fusion_emotions = emotion_service.get_latest_emotions()
        
        # ChatGPT ì‘ë‹µ ìƒì„±
        primary_fusion = max(fusion_emotions, key=fusion_emotions.get)
        logger.info(f"ğŸ’¬ [ChatGPT ì…ë ¥] Late Fusion: {primary_fusion} ({fusion_emotions[primary_fusion]:.1%})")
        
        ai_response = get_chatgpt_response(user_message, fusion_emotions, modality_emotions)
        
        return jsonify({
            "message": ai_response,
            "fusion_emotions": fusion_emotions,
            "modality_emotions": modality_emotions,
            "timestamp": datetime.now().isoformat(),
            "is_voice": is_voice
        })
        
    except Exception as e:
        logger.error(f"ì±„íŒ… API ì—ëŸ¬: {e}")
        return jsonify({"error": "ì„œë²„ ì˜¤ë¥˜"}), 500


@app.route('/api/chat/history')
def get_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
    return jsonify({
        "history": chat_history[-20:],
        "count": len(chat_history)
    })


@app.route('/api/chat/clear', methods=['POST'])
def clear_chat_history():
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
    global chat_history
    chat_history = []
    return jsonify({"status": "success"})


@app.route('/api/service/status')
def service_status():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    return jsonify({
        "running": emotion_service.is_running,
        "models_loaded": emotion_service.models_loaded,
        "timestamp": datetime.now().isoformat()
    })


# =============================================================================
# ì•± ì‹œì‘/ì¢…ë£Œ
# =============================================================================

def on_startup():
    """ì•± ì‹œì‘"""
    logger.info("="*80)
    logger.info("ğŸŒ ì‹¤ì‹œê°„ ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„ ì–´í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
    logger.info("="*80)
    emotion_service.start()


def on_shutdown():
    """ì•± ì¢…ë£Œ"""
    logger.info("ì•± ì¢…ë£Œ ì¤‘...")
    emotion_service.stop()


if __name__ == '__main__':
    import os
    try:
        on_startup()
        port = int(os.environ.get('PORT', 5001))
        app.run(
            host='0.0.0.0',
            port=port,
            debug=False,
            threaded=True
        )
    except KeyboardInterrupt:
        logger.info("\nì‚¬ìš©ì ì¤‘ë‹¨")
    finally:
        on_shutdown()

