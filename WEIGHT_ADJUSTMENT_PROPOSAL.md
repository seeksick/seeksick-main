# ⚖️ Late Fusion 가중치 조정 제안

## 📊 모델 성능 분석

### 현재 성능

| 모델 | 정확도 | 강점 | 약점 |
|------|--------|------|------|
| **ResNet18 (얼굴)** | 74.37% | happy, surprised 특히 높음 | - |
| **Wav2Vec2 (음성)** | ~65% | - | - |
| **KoBERT (텍스트)** | ~66% | - | - |

**평균 정확도:** (74.37 + 65 + 66) / 3 = **68.46%**

---

## 🎯 가중치 조정 제안

### 제안 1: **성능 비례 가중치 (Performance-based)**

#### 📐 수식

```
가중치_i = 정확도_i / Σ(모든 정확도)
```

#### 계산

```python
총합 = 74.37 + 65 + 66 = 205.37

W_face = 74.37 / 205.37 = 0.362  (36.2%)
W_voice = 65 / 205.37 = 0.317    (31.7%)
W_text = 66 / 205.37 = 0.321     (32.1%)

# 검증
0.362 + 0.317 + 0.321 = 1.000 ✓
```

#### ✅ 장점
- 성능이 좋은 모델의 영향력 증가
- 수학적으로 명확
- 구현 간단

#### ❌ 단점
- 얼굴 모델에 과도하게 의존 (36% vs 31-32%)
- 차이가 크지 않아 효과가 미미할 수 있음

---

### 제안 2: **정규화된 성능 가중치 (Normalized Performance)**

#### 📐 수식

성능 차이를 정규화하여 극단적인 편향 방지

```
정규화_정확도_i = (정확도_i - 최소값) / (최대값 - 최소값)
가중치_i = (1 + 정규화_정확도_i) / Σ(1 + 정규화_정확도들)
```

#### 계산

```python
최소 = 65, 최대 = 74.37

# 정규화
norm_face = (74.37 - 65) / (74.37 - 65) = 1.000
norm_voice = (65 - 65) / (74.37 - 65) = 0.000
norm_text = (66 - 65) / (74.37 - 65) = 0.107

# 가중치 계산
총합 = (1 + 1.000) + (1 + 0.000) + (1 + 0.107) = 4.107

W_face = (1 + 1.000) / 4.107 = 0.487  (48.7%)
W_voice = (1 + 0.000) / 4.107 = 0.244  (24.4%)
W_text = (1 + 0.107) / 4.107 = 0.270  (27.0%)

# 검증
0.487 + 0.244 + 0.270 = 1.001 ≈ 1.000 ✓
```

#### ✅ 장점
- 성능 차이를 더 강조
- 최고 성능 모델 우대

#### ❌ 단점
- 얼굴 모델에 너무 의존적 (48.7%)
- 음성/텍스트 모델이 과소평가될 수 있음

---

### 제안 3: **제곱근 스케일링 (Square Root Scaling)** ⭐ **추천**

#### 📐 수식

성능 차이를 완화하여 편향 최소화

```
가중치_i = √정확도_i / Σ(√모든 정확도)
```

#### 계산

```python
sqrt_face = √74.37 = 8.624
sqrt_voice = √65 = 8.062
sqrt_text = √66 = 8.124

총합 = 8.624 + 8.062 + 8.124 = 24.810

W_face = 8.624 / 24.810 = 0.348  (34.8%)
W_voice = 8.062 / 24.810 = 0.325  (32.5%)
W_text = 8.124 / 24.810 = 0.327  (32.7%)

# 검증
0.348 + 0.325 + 0.327 = 1.000 ✓
```

#### ✅ 장점
- **편향 최소화**: 차이가 크지 않음 (34.8% vs 32.5-32.7%)
- **균형적**: 모든 모달리티가 적절한 영향력 유지
- **수학적 근거**: 제곱근은 차이를 완화하는 표준 방법

#### ❌ 단점
- 성능 차이가 약간 희석됨

---

### 제안 4: **로그 스케일링 (Log Scaling)**

#### 📐 수식

극단적인 편향 방지

```
가중치_i = log(1 + 정확도_i) / Σ(log(1 + 모든 정확도))
```

#### 계산

```python
log_face = log(1 + 74.37) = log(75.37) = 4.322
log_voice = log(1 + 65) = log(66) = 4.190
log_text = log(1 + 66) = log(67) = 4.205

총합 = 4.322 + 4.190 + 4.205 = 12.717

W_face = 4.322 / 12.717 = 0.340  (34.0%)
W_voice = 4.190 / 12.717 = 0.329  (32.9%)
W_text = 4.205 / 12.717 = 0.331  (33.1%)

# 검증
0.340 + 0.329 + 0.331 = 1.000 ✓
```

#### ✅ 장점
- **가장 균형적**: 거의 동등한 가중치
- 편향 거의 없음

#### ❌ 단점
- 성능 차이가 거의 반영 안 됨
- 좋은 모델의 장점이 희석됨

---

### 제안 5: **하이브리드 방식 (Hybrid)** ⭐⭐ **강력 추천**

#### 📐 수식

성능과 균형의 절충안

```
가중치_i = α × (정확도_i / Σ정확도) + (1-α) × (1/M)

α = 조정 파라미터 (0~1)
M = 모달리티 개수 (3)
```

#### 계산 (α = 0.6 권장)

```python
# 성능 비례 부분
perf_face = 74.37 / 205.37 = 0.362
perf_voice = 65 / 205.37 = 0.317
perf_text = 66 / 205.37 = 0.321

# 균등 부분
equal = 1/3 = 0.333

# 하이브리드 (α = 0.6)
W_face = 0.6 × 0.362 + 0.4 × 0.333 = 0.350  (35.0%)
W_voice = 0.6 × 0.317 + 0.4 × 0.333 = 0.323  (32.3%)
W_text = 0.6 × 0.321 + 0.4 × 0.333 = 0.326  (32.6%)

# 검증
0.350 + 0.323 + 0.326 = 0.999 ≈ 1.000 ✓
```

#### α 값에 따른 변화

| α | W_face | W_voice | W_text | 특징 |
|---|--------|---------|--------|------|
| 0.0 | 0.333 | 0.333 | 0.333 | 완전 균등 |
| 0.3 | 0.342 | 0.328 | 0.330 | 약간 성능 반영 |
| **0.6** | **0.350** | **0.323** | **0.326** | **균형적** ⭐ |
| 0.8 | 0.356 | 0.320 | 0.324 | 성능 우선 |
| 1.0 | 0.362 | 0.317 | 0.321 | 완전 성능 기반 |

#### ✅ 장점
- **조정 가능**: α로 균형 조절
- **최적 균형**: 성능도 반영, 편향도 최소화
- **실전적**: 실제 시스템에 가장 적합

---

## 📊 제안 비교표

| 방법 | W_face | W_voice | W_text | 편향도 | 성능반영 | 추천도 |
|------|--------|---------|--------|--------|----------|--------|
| 현재 (균등) | 33.3% | 33.3% | 33.3% | ⭐⭐⭐⭐⭐ | ☆☆☆☆☆ | ⭐⭐⭐ |
| 성능 비례 | 36.2% | 31.7% | 32.1% | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |
| 정규화 | 48.7% | 24.4% | 27.0% | ⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐ |
| **제곱근** | **34.8%** | **32.5%** | **32.7%** | **⭐⭐⭐⭐⭐** | **⭐⭐⭐⭐** | **⭐⭐⭐⭐** |
| 로그 | 34.0% | 32.9% | 33.1% | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐ |
| **하이브리드** | **35.0%** | **32.3%** | **32.6%** | **⭐⭐⭐⭐⭐** | **⭐⭐⭐⭐** | **⭐⭐⭐⭐⭐** |

---

## 🎯 최종 추천

### 🥇 1순위: **하이브리드 방식 (α = 0.6)**

```python
W_face = 0.350   # 35.0%
W_voice = 0.323  # 32.3%
W_text = 0.326   # 32.6%
```

**이유:**
- ✅ 성능 차이를 적절히 반영 (74% vs 65-66%)
- ✅ 편향 최소화 (최대 3.5% 차이)
- ✅ 조정 가능 (α 값으로 튜닝)
- ✅ 실전에서 검증된 방법

### 🥈 2순위: **제곱근 스케일링**

```python
W_face = 0.348   # 34.8%
W_voice = 0.325  # 32.5%
W_text = 0.327   # 32.7%
```

**이유:**
- ✅ 구현 간단
- ✅ 수학적으로 깔끔
- ✅ 편향 매우 적음 (최대 2.5% 차이)

---

## 💻 구현 코드

### 하이브리드 방식 구현

```python
class LateFusion:
    def __init__(self, interval: float = FUSION_INTERVAL):
        self.interval = interval
        self.face_buffer = []
        self.voice_buffer = []
        self.text_buffer = []
        self.last_fusion_time = time.time()
        
        # 가중치 설정 (하이브리드, α = 0.6)
        self.weights = {
            'face': 0.350,
            'voice': 0.323,
            'text': 0.326
        }
    
    def fuse_emotions(self):
        available_modalities = {}
        fused_probs = np.zeros(len(EMOTIONS))
        total_weight = 0
        
        # 1. 얼굴 감정 (가중치 적용)
        if self.face_buffer:
            face_avg = np.mean(self.face_buffer, axis=0)
            fused_probs += face_avg * self.weights['face']
            total_weight += self.weights['face']
            available_modalities['face'] = len(self.face_buffer)
        
        # 2. 음성 감정 (가중치 적용)
        if self.voice_buffer:
            voice_avg = np.mean(self.voice_buffer, axis=0)
            fused_probs += voice_avg * self.weights['voice']
            total_weight += self.weights['voice']
            available_modalities['voice'] = len(self.voice_buffer)
        
        # 3. 텍스트 감정 (가중치 적용)
        if self.text_buffer:
            text_avg = np.mean(self.text_buffer, axis=0)
            fused_probs += text_avg * self.weights['text']
            total_weight += self.weights['text']
            available_modalities['text'] = len(self.text_buffer)
        
        if total_weight == 0:
            return None
        
        # 정규화 (확률 합 = 1.0 보장)
        fused_probs /= total_weight
        
        # 최종 감정 추출
        max_idx = np.argmax(fused_probs)
        final_emotion = EMOTIONS[max_idx]
        confidence = float(fused_probs[max_idx])
        
        return final_emotion, confidence, available_modalities
```

### 제곱근 스케일링 구현

```python
class LateFusion:
    def __init__(self, interval: float = FUSION_INTERVAL):
        self.interval = interval
        self.face_buffer = []
        self.voice_buffer = []
        self.text_buffer = []
        self.last_fusion_time = time.time()
        
        # 가중치 설정 (제곱근 기반)
        accuracies = {'face': 74.37, 'voice': 65, 'text': 66}
        sqrt_sum = sum(np.sqrt(acc) for acc in accuracies.values())
        
        self.weights = {
            'face': np.sqrt(74.37) / sqrt_sum,   # 0.348
            'voice': np.sqrt(65) / sqrt_sum,     # 0.325
            'text': np.sqrt(66) / sqrt_sum       # 0.327
        }
    
    # fuse_emotions()는 하이브리드와 동일
```

---

## 🧪 예측 효과

### 시나리오: 얼굴만 happy 강하게 예측

**입력:**
```python
Face:  [0.9, 0.02, 0.03, 0.03, 0.02]  # happy 강함
Voice: [0.3, 0.4, 0.15, 0.1, 0.05]    # depressed 약함
Text:  [0.35, 0.35, 0.15, 0.1, 0.05]  # happy/depressed 혼재
```

**현재 (균등 가중치):**
```python
Final = ([0.9, 0.02, 0.03, 0.03, 0.02] +
         [0.3, 0.4, 0.15, 0.1, 0.05] +
         [0.35, 0.35, 0.15, 0.1, 0.05]) / 3
      = [0.517, 0.257, 0.110, 0.077, 0.040]

→ happy (51.7%)  # 불확실
```

**하이브리드 (추천):**
```python
Final = [0.9, 0.02, 0.03, 0.03, 0.02] × 0.350 +
        [0.3, 0.4, 0.15, 0.1, 0.05] × 0.323 +
        [0.35, 0.35, 0.15, 0.1, 0.05] × 0.326
      = [0.315, 0.007, 0.011, 0.011, 0.007] +
        [0.097, 0.129, 0.048, 0.032, 0.016] +
        [0.114, 0.114, 0.049, 0.033, 0.016]
      = [0.526, 0.250, 0.108, 0.076, 0.039]

→ happy (52.6%)  # 약간 개선
```

**제곱근:**
```python
Final = [0.9, 0.02, 0.03, 0.03, 0.02] × 0.348 +
        [0.3, 0.4, 0.15, 0.1, 0.05] × 0.325 +
        [0.35, 0.35, 0.15, 0.1, 0.05] × 0.327
      = [0.524, 0.251, 0.109, 0.076, 0.039]

→ happy (52.4%)  # 비슷한 효과
```

---

## 🎓 결론

### ✅ 최종 권장사항

**1순위: 하이브리드 (α = 0.6)**
```python
face: 35.0%, voice: 32.3%, text: 32.6%
```
- 성능과 공정성의 최적 균형
- 실전에서 검증된 방법
- 조정 가능 (α 튜닝)

**2순위: 제곱근 스케일링**
```python
face: 34.8%, voice: 32.5%, text: 32.7%
```
- 구현 간단
- 수학적으로 깔끔
- 충분히 균형적

### 📝 구현 팁

1. **초기에는 하이브리드 α = 0.6 사용**
2. **실제 데이터로 테스트 후 조정**
3. **특정 감정(happy, surprised)이 과대예측되면 α 감소**
4. **전반적인 성능 향상 원하면 α 증가**

### 🔬 실험 추천

각 방법을 테스트 데이터로 평가:
1. 전체 정확도
2. 감정별 F1 score
3. 편향도 (감정별 예측 분포)

**가장 균형잡힌 방법을 선택하세요!**

---

**작성:** 2025년 10월 27일  
**기반:** 모델 정확도 - ResNet18(74.37%), Wav2Vec2(65%), KoBERT(66%)

